{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mouktik05/research/blob/main/mouktik_cdna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0BVxpP263neJ",
        "outputId": "932c629c-522d-4487-93bd-2cc36999e970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.83\n"
          ]
        }
      ],
      "source": [
        "pip install biopython requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZU2B8qY9c0t"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB-AIPaK3bvY"
      },
      "outputs": [],
      "source": [
        "def get_transcript_exons(transcript_id):\n",
        "    \"\"\"Fetch exon information for a given Ensembl transcript ID.\"\"\"\n",
        "    #url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    ##url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    url = f\"https://grch37.rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    #https://grch37.rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #https://rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #response = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
        "    response = requests.get(url, json={\"start\": \"value\"})\n",
        "    print(\"url\",url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
        "    return response.json()\n",
        "\n",
        "def map_cdna_to_genomic(transcript_id, cdna_position):\n",
        "    \"\"\"Map a cDNA position to a genomic coordinate using Ensembl.\"\"\"\n",
        "    exons = get_transcript_exons(transcript_id)\n",
        "    total_cdna_len = 0\n",
        "    for exon in sorted(exons, key=lambda x: x['start']):\n",
        "        exon_cdna_start = total_cdna_len + 1\n",
        "        exon_cdna_end = total_cdna_len + exon['end'] - exon['start'] + 1\n",
        "        total_cdna_len = exon_cdna_end\n",
        "\n",
        "        if exon_cdna_start <= cdna_position <= exon_cdna_end:\n",
        "            genomic_pos = exon['start'] + (cdna_position - exon_cdna_start)\n",
        "            return exon['seq_region_name'], genomic_pos, exon['strand']\n",
        "\n",
        "    raise ValueError(f\"cDNA position {cdna_position} out of range for transcript {transcript_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0I385Ff4SdG",
        "outputId": "8c67fe04-8949-4edc-91f1-0cf899a82846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "url https://grch37.rest.ensembl.org/overlap/id/ENST00000050961?feature=gene;content-type=application/json\n",
            "Chromosome: 8, Genomic Position: 77408808, Strand: -1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "transcript_id = \"ENST00000050961\"  # Replace with your transcript ID for USP28\n",
        "cdna_position = 5374  # Replace with your cDNA position\n",
        "chromosome, genomic_position, strand = map_cdna_to_genomic(transcript_id, cdna_position)\n",
        "print(f\"Chromosome: {chromosome}, Genomic Position: {genomic_position}, Strand: {strand}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fY3cMzWmvZW"
      },
      "outputs": [],
      "source": [
        "# prompt: in the below cell, ignore exception in with loop and continue with other records\n",
        "\n",
        "transcript_id = \"ENST00000003302\"  # Replace with your transcript ID for USP28\n",
        "cdna_position = 2194  # Replace with your cDNA position\n",
        "\n",
        "try:\n",
        "    chromosome, genomic_position, strand = map_cdna_to_genomic(transcript_id, cdna_position)\n",
        "    print(f\"Chromosome: {chromosome}, Genomic Position: {genomic_position}, Strand: {strand}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error processing transcript {transcript_id}: {e}\")\n",
        "    # Continue with other records\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIBdUunJbkXl"
      },
      "outputs": [],
      "source": [
        "# prompt: python program to read from a CSV, extract column coding_region_effect and write to another file\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "\n",
        "def get_transcript_exons(transcript_id):\n",
        "    \"\"\"Fetch exon information for a given Ensembl transcript ID.\"\"\"\n",
        "    ##url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    ##url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    url = f\"https://grch37.rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    #https://grch37.rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #https://rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #response = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
        "    response = requests.get(url, json={\"start\": \"value\"})\n",
        "    print(\"url\",url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
        "    return response.json()\n",
        "\n",
        "def map_cdna_to_genomic(transcript_id, cdna_position):\n",
        "    \"\"\"Map a cDNA position to a genomic coordinate using Ensembl.\"\"\"\n",
        "    exons = get_transcript_exons(transcript_id)\n",
        "    total_cdna_len = 0\n",
        "    for exon in sorted(exons, key=lambda x: x['start']):\n",
        "        exon_cdna_start = total_cdna_len + 1\n",
        "        exon_cdna_end = total_cdna_len + exon['end'] - exon['start'] + 1\n",
        "        total_cdna_len = exon_cdna_end\n",
        "\n",
        "        if exon_cdna_start <= cdna_position <= exon_cdna_end:\n",
        "            genomic_pos = exon['start'] + (cdna_position - exon_cdna_start)\n",
        "            return exon['seq_region_name'], genomic_pos, exon['strand']\n",
        "\n",
        "    raise ValueError(f\"cDNA position {cdna_position} out of range for transcript {transcript_id}\")\n",
        "\n",
        "\n",
        "def parse_variant(variant_str):\n",
        "    # Define a regular expression pattern to extract information\n",
        "    pattern = r'^(ENST\\d+)\\((\\w+)\\):c\\.(-?\\d+)([ACGTNacgtn])>([ACGTNacgtn])$'\n",
        "\n",
        "    # Use regex to match the pattern in the variant string\n",
        "    match = re.match(pattern, variant_str)\n",
        "\n",
        "    if match:\n",
        "        enst = match.group(1)  # ENST ID\n",
        "        gene_name = match.group(2)  # Gene name\n",
        "        position = match.group(3)  # Position\n",
        "        ref_base = match.group(4).upper()  # Reference base\n",
        "        alt_base = match.group(5).upper()  # Alternate base\n",
        "\n",
        "        return enst, gene_name, position, ref_base, alt_base\n",
        "    else:\n",
        "        return 'NA', 'NA', 'NA', 'NA', 'NA'\n",
        "\n",
        "# Open the input CSV file\n",
        "with open('odbfile.csv', 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "\n",
        "    # Open the output file for writing\n",
        "    with open('output37.csv', 'w', newline='') as output_file:\n",
        "        csv_writer = csv.writer(output_file)\n",
        "\n",
        "        # Write the header row\n",
        "        csv_writer.writerow(['MRN','coding_region_effect','enst','gene_name','position','ref_base','alt_base','chromosome', 'genomic_position', 'strand'])\n",
        "\n",
        "        # Iterate through the input rows\n",
        "        for row in csv_reader:\n",
        "            # Extract the 'coding_region_effect' column value\n",
        "            coding_region_effect = row[5]\n",
        "            mrn = row[0]\n",
        "            enst, gene_name, position, ref_base, alt_base = parse_variant(coding_region_effect)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if enst != 'NA':\n",
        "              print(\"position value is \", position)\n",
        "              try:\n",
        "                chromosome, genomic_position, strand = map_cdna_to_genomic(enst, int(position))\n",
        "                # Write the coding region effect value to the output file\n",
        "                csv_writer.writerow([mrn,coding_region_effect,enst,gene_name,position,ref_base,alt_base,chromosome, genomic_position, strand])\n",
        "\n",
        "              except Exception as e:\n",
        "                print(f\"Error processing transcript {enst}: {e}\")\n",
        "                # Continue with other records\n",
        "                pass\n",
        "\n",
        "            else:\n",
        "              chromosome = 'NA'\n",
        "              genomic_position = 'NA'\n",
        "              strand = 'NA'\n",
        "\n",
        "\n",
        "            # Write the coding region effect value to the output file\n",
        "            ##csv_writer.writerow([mrn,coding_region_effect,enst,gene_name,position,ref_base,alt_base,chromosome, genomic_position, strand])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBYF9Hek6990"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hPIrrKSf6_Sy"
      },
      "outputs": [],
      "source": [
        "# prompt: python program to read from a CSV, extract column coding_region_effect and write to another file\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "\n",
        "def get_transcript_exons(transcript_id):\n",
        "    \"\"\"Fetch exon information for a given Ensembl transcript ID.\"\"\"\n",
        "    ##url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    ##url = f\"https://grch37.rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    #https://grch37.rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #https://rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #response = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
        "    response = requests.get(url, json={\"start\": \"value\"})\n",
        "    print(\"url\",url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
        "    return response.json()\n",
        "\n",
        "def map_cdna_to_genomic(transcript_id, cdna_position):\n",
        "    \"\"\"Map a cDNA position to a genomic coordinate using Ensembl.\"\"\"\n",
        "    exons = get_transcript_exons(transcript_id)\n",
        "    total_cdna_len = 0\n",
        "    for exon in sorted(exons, key=lambda x: x['start']):\n",
        "        exon_cdna_start = total_cdna_len + 1\n",
        "        exon_cdna_end = total_cdna_len + exon['end'] - exon['start'] + 1\n",
        "        total_cdna_len = exon_cdna_end\n",
        "\n",
        "        if exon_cdna_start <= cdna_position <= exon_cdna_end:\n",
        "            genomic_pos = exon['start'] + (cdna_position - exon_cdna_start)\n",
        "            return exon['seq_region_name'], genomic_pos, exon['strand']\n",
        "\n",
        "    raise ValueError(f\"cDNA position {cdna_position} out of range for transcript {transcript_id}\")\n",
        "\n",
        "\n",
        "def parse_variant(variant_str):\n",
        "    # Define a regular expression pattern to extract information\n",
        "    pattern = r'^(ENST\\d+)\\((\\w+)\\):c\\.(-?\\d+)([ACGTNacgtn])>([ACGTNacgtn])$'\n",
        "\n",
        "    # Use regex to match the pattern in the variant string\n",
        "    match = re.match(pattern, variant_str)\n",
        "\n",
        "    if match:\n",
        "        enst = match.group(1)  # ENST ID\n",
        "        gene_name = match.group(2)  # Gene name\n",
        "        position = match.group(3)  # Position\n",
        "        ref_base = match.group(4).upper()  # Reference base\n",
        "        alt_base = match.group(5).upper()  # Alternate base\n",
        "\n",
        "        return enst, gene_name, position, ref_base, alt_base\n",
        "    else:\n",
        "        return 'NA', 'NA', 'NA', 'NA', 'NA'\n",
        "\n",
        "# Open the input CSV file\n",
        "with open('odbfile.csv', 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "\n",
        "    # Open the output file for writing\n",
        "    with open('output38.csv', 'w', newline='') as output_file:\n",
        "        csv_writer = csv.writer(output_file)\n",
        "\n",
        "        # Write the header row\n",
        "        csv_writer.writerow(['MRN','coding_region_effect','enst','gene_name','position','ref_base','alt_base','chromosome', 'genomic_position', 'strand'])\n",
        "\n",
        "        # Iterate through the input rows\n",
        "        for row in csv_reader:\n",
        "            # Extract the 'coding_region_effect' column value\n",
        "            coding_region_effect = row[5]\n",
        "            mrn = row[0]\n",
        "            enst, gene_name, position, ref_base, alt_base = parse_variant(coding_region_effect)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if enst != 'NA':\n",
        "              print(\"position value is \", position)\n",
        "              try:\n",
        "                chromosome, genomic_position, strand = map_cdna_to_genomic(enst, int(position))\n",
        "\n",
        "              except Exception as e:\n",
        "                print(f\"Error processing transcript {enst}: {e}\")\n",
        "                # Continue with other records\n",
        "                pass\n",
        "\n",
        "            else:\n",
        "              chromosome = 'NA'\n",
        "              genomic_position = 'NA'\n",
        "              strand = 'NA'\n",
        "\n",
        "\n",
        "            # Write the coding region effect value to the output file\n",
        "            csv_writer.writerow([mrn,coding_region_effect,enst,gene_name,position,ref_base,alt_base,chromosome, genomic_position, strand])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0pGV9QQnGqfw"
      },
      "outputs": [],
      "source": [
        "# prompt: python program to read from a CSV, extract column coding_region_effect and write to another file\n",
        "## Extracting Chromosome, Alt, Ref, and Strand from specific MRNS\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "\n",
        "def get_transcript_exons(transcript_id):\n",
        "    \"\"\"Fetch exon information for a given Ensembl transcript ID.\"\"\"\n",
        "    ##url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    url = f\"https://rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    ##url = f\"https://grch37.rest.ensembl.org/overlap/id/{transcript_id}?feature=gene;content-type=application/json\"\n",
        "    #https://grch37.rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #https://rest.ensembl.org/overlap/id/ENST00000025008?feature=gene;content-type=application/json\n",
        "    #response = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
        "    response = requests.get(url, json={\"start\": \"value\"})\n",
        "    print(\"url\",url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
        "    return response.json()\n",
        "\n",
        "def map_cdna_to_genomic(transcript_id, cdna_position):\n",
        "    \"\"\"Map a cDNA position to a genomic coordinate using Ensembl.\"\"\"\n",
        "    exons = get_transcript_exons(transcript_id)\n",
        "    total_cdna_len = 0\n",
        "    for exon in sorted(exons, key=lambda x: x['start']):\n",
        "        exon_cdna_start = total_cdna_len + 1\n",
        "        exon_cdna_end = total_cdna_len + exon['end'] - exon['start'] + 1\n",
        "        total_cdna_len = exon_cdna_end\n",
        "\n",
        "        if exon_cdna_start <= cdna_position <= exon_cdna_end:\n",
        "            genomic_pos = exon['start'] + (cdna_position - exon_cdna_start)\n",
        "            return exon['seq_region_name'], genomic_pos, exon['strand']\n",
        "\n",
        "    raise ValueError(f\"cDNA position {cdna_position} out of range for transcript {transcript_id}\")\n",
        "\n",
        "\n",
        "def parse_variant(variant_str):\n",
        "    # Define a regular expression pattern to extract information\n",
        "    pattern = r'^(ENST\\d+)\\((\\w+)\\):c\\.(-?\\d+)([ACGTNacgtn])>([ACGTNacgtn])$'\n",
        "\n",
        "    # Use regex to match the pattern in the variant string\n",
        "    match = re.match(pattern, variant_str)\n",
        "\n",
        "    if match:\n",
        "        enst = match.group(1)  # ENST ID\n",
        "        gene_name = match.group(2)  # Gene name\n",
        "        position = match.group(3)  # Position\n",
        "        ref_base = match.group(4).upper()  # Reference base\n",
        "        alt_base = match.group(5).upper()  # Alternate base\n",
        "\n",
        "        return enst, gene_name, position, ref_base, alt_base\n",
        "    else:\n",
        "        return 'NA', 'NA', 'NA', 'NA', 'NA'\n",
        "\n",
        "# Open the input CSV file\n",
        "with open('odbfile.csv', 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "\n",
        "    # Open the output file for writing\n",
        "    with open('output38.csv', 'w', newline='') as output_file:\n",
        "        csv_writer = csv.writer(output_file)\n",
        "\n",
        "        # Write the header row\n",
        "        csv_writer.writerow(['MRN','coding_region_effect','enst','gene_name','position','ref_base','alt_base','chromosome', 'genomic_position', 'strand'])\n",
        "\n",
        "        # Iterate through the input rows\n",
        "        for row in csv_reader:\n",
        "            # Extract the 'coding_region_effect' column value\n",
        "            coding_region_effect = row[5]\n",
        "            mrn = row[0]\n",
        "            enst, gene_name, position, ref_base, alt_base = parse_variant(coding_region_effect)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if enst != 'NA':\n",
        "              print(\"position value is \", position)\n",
        "              try:\n",
        "                chromosome, genomic_position, strand = map_cdna_to_genomic(enst, int(position))\n",
        "\n",
        "              except Exception as e:\n",
        "                print(f\"Error processing transcript {enst}: {e}\")\n",
        "                # Continue with other records\n",
        "                pass\n",
        "\n",
        "            else:\n",
        "              chromosome = 'NA'\n",
        "              genomic_position = 'NA'\n",
        "              strand = 'NA'\n",
        "\n",
        "\n",
        "            # Write the coding region effect value to the output file\n",
        "            csv_writer.writerow([mrn,coding_region_effect,enst,gene_name,position,ref_base,alt_base,chromosome, genomic_position, strand])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the input CSV file path and output directory\n",
        "input_csv_file = 'output_hg37.csv'  # Change this to your input file path\n",
        "output_directory = 'mrn_files'  # Change this to your desired output directory\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "# Read the input CSV file\n",
        "df = pd.read_csv(input_csv_file)\n",
        "\n",
        "# Drop the columns 'Chromosome', 'Genomic Position', 'Strand'\n",
        "df_dropped = df.drop(columns= ['coding_region_effect', 'enst', 'gene_name'])\n",
        "\n",
        "# Group the DataFrame by the 'MRN' column\n",
        "grouped = df_dropped.groupby('MRN')\n",
        "\n",
        "# Iterate over each group and save to a separate .dat file\n",
        "for mrn, group_df in grouped:\n",
        "    output_file = os.path.join(output_directory, f'{mrn}.dat')\n",
        "    # Save the DataFrame to a .dat file with tab separation\n",
        "    group_df.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f'Saved {output_file}')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n7rKTRsvL6o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the input CSV file path and output directory\n",
        "input_csv_file = 'output_hg37.csv'  # Change this to your input file path\n",
        "output_directory = 'mrn_files'  # Change this to your desired output directory\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "# Read the input CSV file\n",
        "df = pd.read_csv(input_csv_file)\n",
        "\n",
        "# Define columns to remove\n",
        "columns_to_remove = ['coding_region_effect', 'enst', 'gene_name', 'position']\n",
        "\n",
        "# Remove specified columns\n",
        "df_filtered = df.drop(columns=columns_to_remove)\n",
        "\n",
        "# Group the DataFrame by the 'MRN' column\n",
        "grouped = df_filtered.groupby('MRN')\n",
        "\n",
        "# Function to format DataFrame for .dat file\n",
        "def format_dataframe_for_dat(df):\n",
        "    # Determine maximum column widths based on header length\n",
        "    col_widths = {col: len(col) for col in df.columns}\n",
        "\n",
        "    # Update column widths with data lengths\n",
        "    for col in df.columns:\n",
        "        col_widths[col] = max(col_widths[col], df[col].astype(str).apply(len).max())\n",
        "\n",
        "    # Format each row\n",
        "    formatted_rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        formatted_row = \" \".join(f\"{str(val).ljust(col_widths[col])}\" for col, val in row.items())\n",
        "        formatted_rows.append(formatted_row)\n",
        "\n",
        "    # Combine header and formatted rows\n",
        "    header_row = \" \".join(f\"{col.ljust(col_widths[col])}\" for col in df.columns)\n",
        "    return \"\\n\".join([header_row] + formatted_rows)\n",
        "\n",
        "# Iterate over each group and save to a separate .dat file\n",
        "for mrn, group_df in grouped:\n",
        "    output_file = os.path.join(output_directory, f'{mrn}.dat')\n",
        "    formatted_data = format_dataframe_for_dat(group_df)\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(formatted_data)\n",
        "\n",
        "    print(f'Saved {output_file}')\n",
        "\n"
      ],
      "metadata": {
        "id": "bnNSYnMXP-CY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "123206c5-cd4b-4b45-b71e-a19ffca6dea1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'output_hg37.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-81d071864acb>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Read the input CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Define columns to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_hg37.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install biopython\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh81JTpOS08-",
        "outputId": "da065569-29df-4521-84fa-dc40c01b3192"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyfaidx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qhOiIp7TOre",
        "outputId": "07cec5c2-b077-4ab7-fb4a-d05ef5430d18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyfaidx\n",
            "  Downloading pyfaidx-0.8.1.2-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (71.0.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (24.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->pyfaidx) (3.20.0)\n",
            "Downloading pyfaidx-0.8.1.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: pyfaidx\n",
            "Successfully installed pyfaidx-0.8.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from Bio.Seq import Seq\n",
        "from pyfaidx import Fasta\n",
        "\n",
        "# Load the reference genome\n",
        " #genome = Fasta('/path/to/your/hg19.fa')\n",
        "\n",
        "genome = Fasta('401428_mouktik.fasta')\n",
        "\n",
        "# Function to get the sequence context and apply reverse complement if necessary\n",
        "def get_ms(chr, pos, strand, alt_allele, sep=\" \"):\n",
        "    # Get the sequence context (3 bp upstream and downstream)\n",
        "    seq = get_ms_gr(chr, pos)\n",
        "    print(\"seq\", seq)\n",
        "    # Convert to Biopython Seq object\n",
        "    seq = Seq(str(seq))\n",
        "    alt_seq = Seq(alt_allele)\n",
        "\n",
        "    # Apply reverse complement if necessary\n",
        "    reverse_mask = any(nucleotide in seq for nucleotide in [\"A\", \"T\", \"C\", \"G\"])\n",
        "    if reverse_mask:\n",
        "        seq = seq.reverse_complement()\n",
        "        alt_seq = alt_seq.reverse_complement()\n",
        "\n",
        "    # Create the result\n",
        "    result = f\"{seq}{sep}{alt_seq}\"\n",
        "    return result\n",
        "\n",
        "# Function to get the sequence context (3 bp upstream and downstream)\n",
        "def get_ms_gr(chr, pos):\n",
        "    # Fetch the 7bp sequence centered around the position\n",
        "    start = pos - 3\n",
        "    end = pos + 3\n",
        "    seq = genome[chr][start:end].seq\n",
        "    return seq\n",
        "\n",
        "# Set working directory\n",
        "os.chdir(\".\")\n",
        "\n",
        "# Get list of files\n",
        "file_names = [f for f in os.listdir() if f.endswith('.txt')]\n",
        "\n",
        "# Process each file\n",
        "for j, file_name in enumerate(file_names):\n",
        "    print(file_name)\n",
        "    print(j + 1)\n",
        "\n",
        "    # Load the data\n",
        "    data = pd.read_csv(file_name, sep=\" \", names=[\"chr\", \"loc\", \"site\", \"mut\", \"strand\"])\n",
        "\n",
        "    # Filter data by chromosome\n",
        "    for chr_num in range(1, 23):\n",
        "        data_chr = data[data['chr'] == chr_num]\n",
        "\n",
        "        # Process each location in the filtered data\n",
        "        for i in data_chr['loc']:\n",
        "            tri_nucl_context = get_ms(f\"chr{chr_num}\", i, \"+\", \"C\")\n",
        "            df = pd.DataFrame({\"loc\": [i], \"triNuclContext\": [tri_nucl_context]})\n",
        "\n",
        "            # Save the result to a file\n",
        "            output_file = f\"/Users/4464689/Desktop/PROJECTS/Moffitt/GhulamIPMNs/Mouktik/sequences3nt/{file_name}\"\n",
        "            df.to_csv(output_file, sep=\"\\t\", mode='a', header=False, index=False)\n",
        "\n",
        "    print(f\"Processed chr{chr_num}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IiRvPXZnjuhx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_dat_to_fasta(dat_file, fasta_file):\n",
        "    with open(dat_file, 'r') as infile, open(fasta_file, 'w') as outfile:\n",
        "        sequence_id = 1  # Starting sequence ID number\n",
        "        for line in infile:\n",
        "            line = line.strip()\n",
        "            if line:  # Ignore empty lines\n",
        "                # If the line contains sequence data, write it in FASTA format\n",
        "                outfile.write(f\">sequence{sequence_id}\\n\")\n",
        "                outfile.write(f\"{line}\\n\")\n",
        "                sequence_id += 1\n",
        "\n",
        "# Example usage\n",
        "convert_dat_to_fasta('401428.dat', '401428_mouktik.fasta')\n"
      ],
      "metadata": {
        "id": "EJiLSNJ6U-OU"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}